{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from extend import *\n",
    "from gradient_descent import *\n",
    "from stochastic_gradient_descent import *\n",
    "from hessian_descent import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook project1.ipynb to script\n",
      "[NbConvertApp] Writing 3198 bytes to project1.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script project1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from proj1_helpers import *\n",
    "from proj1_helpers_tanh import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = np.copy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_by_col = []\n",
    "for i in range(tX.shape[1]):\n",
    "    col = tX[:,i]\n",
    "    places_999 = (col == -999.0)\n",
    "    mean_col = col[col!=-999.0].mean()\n",
    "    col[places_999] = mean_col\n",
    "    tX[:,i] = col\n",
    "    mean_by_col.append(mean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(tX > 0,axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_columns = tX[:,np.all(tX > 0,axis=0)]\n",
    "positive_columns_log = np.log(positive_columns)\n",
    "not_zero_columns = tX[:, np.all(tX != 0,axis=0)]\n",
    "not_zero_columns_inv = 1 / not_zero_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 12)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 241)\n",
      "(250000, 240)\n",
      "(250000, 300)\n"
     ]
    }
   ],
   "source": [
    "degree = 8\n",
    "tX = build_poly(tX, degree)\n",
    "print(tX.shape)\n",
    "tX = tX[:,1:]\n",
    "print(tX.shape)\n",
    "tX = extend(tX,[ np.cos, np.sin, ])\n",
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = np.c_[(tX, positive_columns_log)]\n",
    "tX = np.c_[(tX, not_zero_columns_inv)]\n",
    "tX = np.c_[(tX, not_zero_columns_inv**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 338)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(tX,axis = 0)\n",
    "std = np.std(tX,axis = 0)\n",
    "tX = (tX-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338,)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = np.c_[(np.ones(tX.shape[0]) , tX)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 339)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tanh_gradient_descent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian Descent(0/199): loss=0.4999999999999961, w0=-0.31466404075310245, gamma=1.0\n",
      "Hessian Descent(1/199): loss=0.2739342499228847, w0=-0.3855454565694312, gamma=1.0\n",
      "Hessian Descent(2/199): loss=0.26224915027571016, w0=-0.4297044625462421, gamma=1.0\n",
      "Hessian Descent(3/199): loss=0.25778089999259807, w0=-0.46115103824177717, gamma=1.0\n",
      "Hessian Descent(4/199): loss=0.25548594648926454, w0=-0.4849978235082815, gamma=1.0\n",
      "Hessian Descent(5/199): loss=0.25412646906255226, w0=-0.50380208812776, gamma=1.0\n",
      "Hessian Descent(6/199): loss=0.25323583729505034, w0=-0.5190049700899476, gamma=1.0\n",
      "Hessian Descent(7/199): loss=0.2526239424887645, w0=-0.531560527331757, gamma=1.0\n",
      "Hessian Descent(8/199): loss=0.25216887901004365, w0=-0.54206246700678, gamma=1.0\n",
      "Hessian Descent(9/199): loss=0.25183192737557925, w0=-0.5509837883389, gamma=1.0\n",
      "Hessian Descent(10/199): loss=0.25155663422870744, w0=-0.5586100914894385, gamma=1.0\n",
      "Hessian Descent(11/199): loss=0.25134516942224067, w0=-0.5652179389192029, gamma=1.0\n",
      "Hessian Descent(12/199): loss=0.2511587683473994, w0=-0.5709546176206194, gamma=1.0\n",
      "Hessian Descent(13/199): loss=0.25101356643553285, w0=-0.5760007881039103, gamma=1.0\n",
      "Hessian Descent(14/199): loss=0.25087739665721465, w0=-0.5804339774284772, gamma=1.0\n",
      "Hessian Descent(15/199): loss=0.2507710765804569, w0=-0.584381444616718, gamma=1.0\n",
      "Hessian Descent(16/199): loss=0.2506666801378199, w0=-0.5878832022240257, gamma=1.0\n",
      "Hessian Descent(17/199): loss=0.2505853765606532, w0=-0.591033361362932, gamma=1.0\n",
      "Hessian Descent(18/199): loss=0.25050287143445626, w0=-0.5938510934478788, gamma=1.0\n",
      "Hessian Descent(19/199): loss=0.25043883954678886, w0=-0.5964081853309373, gamma=1.0\n",
      "Hessian Descent(20/199): loss=0.25037228803166, w0=-0.5987121593040078, gamma=1.0\n",
      "Hessian Descent(21/199): loss=0.250320767200192, w0=-0.6008188892186539, gamma=1.0\n",
      "Hessian Descent(22/199): loss=0.25026626579265415, w0=-0.6027294923838324, gamma=1.0\n",
      "Hessian Descent(23/199): loss=0.25022408944477653, w0=-0.6044880451623944, gamma=1.0\n",
      "Hessian Descent(24/199): loss=0.25017890189693326, w0=-0.6060923014113346, gamma=1.0\n",
      "Hessian Descent(25/199): loss=0.2501438450069532, w0=-0.607577352717212, gamma=1.0\n",
      "Hessian Descent(26/199): loss=0.2501059678109553, w0=-0.6089393593296043, gamma=1.0\n",
      "Hessian Descent(27/199): loss=0.2500764149835651, w0=-0.6102064435915564, gamma=1.0\n",
      "Hessian Descent(28/199): loss=0.250044340534181, w0=-0.6113741906868843, gamma=1.0\n",
      "Hessian Descent(29/199): loss=0.250019098672017, w0=-0.6124652479097953, gamma=1.0\n",
      "Hessian Descent(30/199): loss=0.24999167487789994, w0=-0.6134751972791886, gamma=1.0\n",
      "Hessian Descent(31/199): loss=0.24996985507982133, w0=-0.6144223449593984, gamma=1.0\n",
      "Hessian Descent(32/199): loss=0.24994619378564353, w0=-0.6153025814400497, gamma=1.0\n",
      "Hessian Descent(33/199): loss=0.24992712838985182, w0=-0.6161307476103822, gamma=1.0\n",
      "Hessian Descent(34/199): loss=0.2499065402697233, w0=-0.6169032027544888, gamma=1.0\n",
      "Hessian Descent(35/199): loss=0.24988972223961206, w0=-0.6176320067797866, gamma=1.0\n",
      "Hessian Descent(36/199): loss=0.24987166792849744, w0=-0.6183140509152265, gamma=1.0\n",
      "Hessian Descent(37/199): loss=0.24985670716147512, w0=-0.6189591510093271, gamma=1.0\n",
      "Hessian Descent(38/199): loss=0.24984075995416258, w0=-0.6195647261799794, gamma=1.0\n",
      "Hessian Descent(39/199): loss=0.24982735205707784, w0=-0.6201387729148861, gamma=1.0\n",
      "Hessian Descent(40/199): loss=0.24981317048154356, w0=-0.6206791945470338, gamma=1.0\n",
      "Hessian Descent(41/199): loss=0.2498010748836283, w0=-0.6211925093561741, gamma=1.0\n",
      "Hessian Descent(42/199): loss=0.24978838349181812, w0=-0.6216770445822399, gamma=1.0\n",
      "Hessian Descent(43/199): loss=0.24977740819316896, w0=-0.6221381176630473, gamma=1.0\n",
      "Hessian Descent(44/199): loss=0.24976598375174147, w0=-0.6225744166554834, gamma=1.0\n",
      "Hessian Descent(45/199): loss=0.2497559742193067, w0=-0.6229902844178871, gamma=1.0\n",
      "Hessian Descent(46/199): loss=0.24974563502331645, w0=-0.6233847103058, gamma=1.0\n",
      "Hessian Descent(47/199): loss=0.24973646576223785, w0=-0.6237612467825577, gamma=1.0\n",
      "Hessian Descent(48/199): loss=0.2497270631144966, w0=-0.6241191310348148, gamma=1.0\n",
      "Hessian Descent(49/199): loss=0.24971863115941892, w0=-0.6244612745970153, gamma=1.0\n",
      "Hessian Descent(50/199): loss=0.24971004255738272, w0=-0.6247871158226181, gamma=1.0\n",
      "Hessian Descent(51/199): loss=0.2497022624743414, w0=-0.6250990462399585, gamma=1.0\n",
      "Hessian Descent(52/199): loss=0.24969438623596407, w0=-0.6253966654475387, gamma=1.0\n",
      "Hessian Descent(53/199): loss=0.2496871863252858, w0=-0.6256819426818593, gamma=1.0\n",
      "Hessian Descent(54/199): loss=0.24967993738072733, w0=-0.6259546052132609, gamma=1.0\n",
      "Hessian Descent(55/199): loss=0.24967325680414626, w0=-0.6262162788644258, gamma=1.0\n",
      "Hessian Descent(56/199): loss=0.24966656341145357, w0=-0.6264667907484845, gamma=1.0\n",
      "Hessian Descent(57/199): loss=0.24966035000927073, w0=-0.6267074870112204, gamma=1.0\n",
      "Hessian Descent(58/199): loss=0.24965415119649778, w0=-0.6269382717862788, gamma=1.0\n",
      "Hessian Descent(59/199): loss=0.24964835982983768, w0=-0.6271602630708281, gamma=1.0\n",
      "Hessian Descent(60/199): loss=0.24964260338610816, w0=-0.627373423551765, gamma=1.0\n",
      "Hessian Descent(61/199): loss=0.24963719465815265, w0=-0.6275786847867469, gamma=1.0\n",
      "Hessian Descent(62/199): loss=0.24963183556170343, w0=-0.6277760532128492, gamma=1.0\n",
      "Hessian Descent(63/199): loss=0.2496267748343737, w0=-0.6279663077239501, gamma=1.0\n",
      "Hessian Descent(64/199): loss=0.24962177400687713, w0=-0.6281494867562467, gamma=1.0\n",
      "Hessian Descent(65/199): loss=0.24961703063188617, w0=-0.628326243950891, gamma=1.0\n",
      "Hessian Descent(66/199): loss=0.24961235395152628, w0=-0.6284966404903866, gamma=1.0\n",
      "Hessian Descent(67/199): loss=0.2496079006657953, w0=-0.6286612270163555, gamma=1.0\n",
      "Hessian Descent(68/199): loss=0.24960351817893034, w0=-0.6288200802599228, gamma=1.0\n",
      "Hessian Descent(69/199): loss=0.24959933062270234, w0=-0.6289736659459392, gamma=1.0\n",
      "Hessian Descent(70/199): loss=0.24959521591060918, w0=-0.6291220707958524, gamma=1.0\n",
      "Hessian Descent(71/199): loss=0.2495912722390104, w0=-0.629265690339247, gamma=1.0\n",
      "Hessian Descent(72/199): loss=0.24958740190324047, w0=-0.6294046170247757, gamma=1.0\n",
      "Hessian Descent(73/199): loss=0.24958368246900203, w0=-0.6295391882009755, gamma=1.0\n",
      "Hessian Descent(74/199): loss=0.24958003570990764, w0=-0.629669498829843, gamma=1.0\n",
      "Hessian Descent(75/199): loss=0.2495765227971961, w0=-0.6297958378842953, gamma=1.0\n",
      "Hessian Descent(76/199): loss=0.24957308106564413, w0=-0.6299183004476093, gamma=1.0\n",
      "Hessian Descent(77/199): loss=0.24956975866901804, w0=-0.6300371351206145, gamma=1.0\n",
      "Hessian Descent(78/199): loss=0.24956650537144864, w0=-0.6301524353934562, gamma=1.0\n",
      "Hessian Descent(79/199): loss=0.24956335900583648, w0=-0.6302644160479189, gamma=1.0\n",
      "Hessian Descent(80/199): loss=0.24956027926315322, w0=-0.6303731677315202, gamma=1.0\n",
      "Hessian Descent(81/199): loss=0.24955729579780056, w0=-0.6304788768140137, gamma=1.0\n",
      "Hessian Descent(82/199): loss=0.24955437623138477, w0=-0.6305816302684074, gamma=1.0\n",
      "Hessian Descent(83/199): loss=0.24955154375070943, w0=-0.6306815904711623, gamma=1.0\n",
      "Hessian Descent(84/199): loss=0.24954877230806938, w0=-0.6307788401807445, gamma=1.0\n",
      "Hessian Descent(85/199): loss=0.2495460799808969, w0=-0.6308735214613022, gamma=1.0\n",
      "Hessian Descent(86/199): loss=0.24954344578209883, w0=-0.630965712528665, gamma=1.0\n",
      "Hessian Descent(87/199): loss=0.24954088375409192, w0=-0.631055538167139, gamma=1.0\n",
      "Hessian Descent(88/199): loss=0.24953837695777215, w0=-0.6311430719202303, gamma=1.0\n",
      "Hessian Descent(89/199): loss=0.24953593625413575, w0=-0.6312284238048546, gamma=1.0\n",
      "Hessian Descent(90/199): loss=0.24953354794230187, w0=-0.6313116626831832, gamma=1.0\n",
      "Hessian Descent(91/199): loss=0.24953122038090797, w0=-0.631392885906063, gamma=1.0\n",
      "Hessian Descent(92/199): loss=0.2495289424592943, w0=-0.6314721577194584, gamma=1.0\n",
      "Hessian Descent(93/199): loss=0.24952672057178976, w0=-0.6315495645787903, gamma=1.0\n",
      "Hessian Descent(94/199): loss=0.24952454568267188, w0=-0.6316251662644223, gamma=1.0\n",
      "Hessian Descent(95/199): loss=0.24952242264631203, w0=-0.6316990397939608, gamma=1.0\n",
      "Hessian Descent(96/199): loss=0.24952034409127602, w0=-0.6317712406780812, gamma=1.0\n",
      "Hessian Descent(97/199): loss=0.24951831366669572, w0=-0.631841837755431, gamma=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian Descent(98/199): loss=0.2495163253390208, w0=-0.6319108824661273, gamma=1.0\n",
      "Hessian Descent(99/199): loss=0.24951438181640112, w0=-0.6319784365268407, gamma=1.0\n",
      "Hessian Descent(100/199): loss=0.24951247814048613, w0=-0.6320445475498389, gamma=1.0\n",
      "Hessian Descent(101/199): loss=0.24951061628905252, w0=-0.6321092710104526, gamma=1.0\n",
      "Hessian Descent(102/199): loss=0.24950879216874905, w0=-0.6321726509378407, gamma=1.0\n",
      "Hessian Descent(103/199): loss=0.2495070071923955, w0=-0.6322347373331738, gamma=1.0\n",
      "Hessian Descent(104/199): loss=0.24950525796405087, w0=-0.6322955708847436, gamma=1.0\n",
      "Hessian Descent(105/199): loss=0.24950354546117134, w0=-0.6323551967816248, gamma=1.0\n",
      "Hessian Descent(106/199): loss=0.24950186685211548, w0=-0.632413652587842, gamma=1.0\n",
      "Hessian Descent(107/199): loss=0.24950022278035716, w0=-0.6324709792466077, gamma=1.0\n",
      "Hessian Descent(108/199): loss=0.24949861087277286, w0=-0.632527211444604, gamma=1.0\n",
      "Hessian Descent(109/199): loss=0.24949703151536606, w0=-0.6325823863480048, gamma=1.0\n",
      "Hessian Descent(110/199): loss=0.24949548271138122, w0=-0.6326365359902364, gamma=1.0\n",
      "Hessian Descent(111/199): loss=0.24949396465072796, w0=-0.6326896941892409, gamma=1.0\n",
      "Hessian Descent(112/199): loss=0.24949247564348667, w0=-0.6327418905232699, gamma=1.0\n",
      "Hessian Descent(113/199): loss=0.24949101573392252, w0=-0.6327931558240121, gamma=1.0\n",
      "Hessian Descent(114/199): loss=0.24948958348160982, w0=-0.6328435174144684, gamma=1.0\n",
      "Hessian Descent(115/199): loss=0.24948817882499635, w0=-0.6328930034647725, gamma=1.0\n",
      "Hessian Descent(116/199): loss=0.24948680052786995, w0=-0.6329416392203682, gamma=1.0\n",
      "Hessian Descent(117/199): loss=0.24948544845207624, w0=-0.6329894504662366, gamma=1.0\n",
      "Hessian Descent(118/199): loss=0.24948412153142768, w0=-0.6330364605457272, gamma=1.0\n",
      "Hessian Descent(119/199): loss=0.24948281957145252, w0=-0.6330826931025909, gamma=1.0\n",
      "Hessian Descent(120/199): loss=0.24948154164869518, w0=-0.633128169735534, gamma=1.0\n",
      "Hessian Descent(121/199): loss=0.24948028752988943, w0=-0.6331729121685893, gamma=1.0\n",
      "Hessian Descent(122/199): loss=0.24947905641132362, w0=-0.6332169403944556, gamma=1.0\n",
      "Hessian Descent(123/199): loss=0.24947784803489836, w0=-0.6332602744060076, gamma=1.0\n",
      "Hessian Descent(124/199): loss=0.2494766616936458, w0=-0.6333029327284775, gamma=1.0\n",
      "Hessian Descent(125/199): loss=0.24947549711854317, w0=-0.6333449337917644, gamma=1.0\n",
      "Hessian Descent(126/199): loss=0.2494743536846967, w0=-0.6333862947778672, gamma=1.0\n",
      "Hessian Descent(127/199): loss=0.24947323111708747, w0=-0.6334270327060224, gamma=1.0\n",
      "Hessian Descent(128/199): loss=0.24947212886247117, w0=-0.6334671635250076, gamma=1.0\n",
      "Hessian Descent(129/199): loss=0.24947104664372563, w0=-0.6335067029767698, gamma=1.0\n",
      "Hessian Descent(130/199): loss=0.24946998397007597, w0=-0.6335456658836687, gamma=1.0\n",
      "Hessian Descent(131/199): loss=0.249468940566684, w0=-0.6335840668248695, gamma=1.0\n",
      "Hessian Descent(132/199): loss=0.24946791599661688, w0=-0.6336219195908439, gamma=1.0\n",
      "Hessian Descent(133/199): loss=0.24946690998976523, w0=-0.6336592377111377, gamma=1.0\n",
      "Hessian Descent(134/199): loss=0.249465922155409, w0=-0.6336960340310294, gamma=1.0\n",
      "Hessian Descent(135/199): loss=0.24946495223319326, w0=-0.6337323211176412, gamma=1.0\n",
      "Hessian Descent(136/199): loss=0.24946399986975537, w0=-0.6337681109503934, gamma=1.0\n",
      "Hessian Descent(137/199): loss=0.24946306481768704, w0=-0.6338034152291926, gamma=1.0\n",
      "Hessian Descent(138/199): loss=0.24946214675569917, w0=-0.6338382451277822, gamma=1.0\n",
      "Hessian Descent(139/199): loss=0.24946124544945986, w0=-0.6338726115623526, gamma=1.0\n",
      "Hessian Descent(140/199): loss=0.24946036060656102, w0=-0.6339065249735569, gamma=1.0\n",
      "Hessian Descent(141/199): loss=0.24945949200615175, w0=-0.6339399955497813, gamma=1.0\n",
      "Hessian Descent(142/199): loss=0.24945863938106935, w0=-0.6339730330609078, gamma=1.0\n",
      "Hessian Descent(143/199): loss=0.2494578025244078, w0=-0.6340056470368888, gamma=1.0\n",
      "Hessian Descent(144/199): loss=0.24945698119216034, w0=-0.6340378466301005, gamma=1.0\n",
      "Hessian Descent(145/199): loss=0.24945617518936758, w0=-0.6340696407578654, gamma=1.0\n",
      "Hessian Descent(146/199): loss=0.24945538429380115, w0=-0.634101038009348, gamma=1.0\n",
      "Hessian Descent(147/199): loss=0.24945460832318134, w0=-0.6341320467436936, gamma=1.0\n",
      "Hessian Descent(148/199): loss=0.24945384707295643, w0=-0.6341626750249455, gamma=1.0\n",
      "Hessian Descent(149/199): loss=0.2494531003741346, w0=-0.6341929307111513, gamma=1.0\n",
      "Hessian Descent(150/199): loss=0.24945236804019846, w0=-0.6342228213768623, gamma=1.0\n",
      "Hessian Descent(151/199): loss=0.24945164991245178, w0=-0.634252354409668, gamma=1.0\n",
      "Hessian Descent(152/199): loss=0.24945094581934996, w0=-0.6342815369473832, gamma=1.0\n",
      "Hessian Descent(153/199): loss=0.2494502556154311, w0=-0.634310375940508, gamma=1.0\n",
      "Hessian Descent(154/199): loss=0.2494495791431528, w0=-0.6343388781137606, gamma=1.0\n",
      "Hessian Descent(155/199): loss=0.2494489162660285, w0=-0.6343670500197701, gamma=1.0\n",
      "Hessian Descent(156/199): loss=0.24944826684248325, w0=-0.634394898007413, gamma=1.0\n",
      "Hessian Descent(157/199): loss=0.24944763074462775, w0=-0.6344224282494338, gamma=1.0\n",
      "Hessian Descent(158/199): loss=0.24944700784206023, w0=-0.6344496467474513, gamma=1.0\n",
      "Hessian Descent(159/199): loss=0.2494463980185561, w0=-0.6344765593409468, gamma=1.0\n",
      "Hessian Descent(160/199): loss=0.24944580115456944, w0=-0.6345031716961601, gamma=1.0\n",
      "Hessian Descent(161/199): loss=0.249445217142176, w0=-0.6345294893292227, gamma=1.0\n",
      "Hessian Descent(162/199): loss=0.24944464587308604, w0=-0.6345555176064933, gamma=1.0\n",
      "Hessian Descent(163/199): loss=0.24944408724778652, w0=-0.6345812617533186, gamma=1.0\n",
      "Hessian Descent(164/199): loss=0.24944354116676154, w0=-0.6346067268475166, gamma=1.0\n",
      "Hessian Descent(165/199): loss=0.24944300754116777, w0=-0.6346319178376617, gamma=1.0\n",
      "Hessian Descent(166/199): loss=0.24944248627796997, w0=-0.6346568395350624, gamma=1.0\n",
      "Hessian Descent(167/199): loss=0.24944197729640852, w0=-0.6346814966322645, gamma=1.0\n",
      "Hessian Descent(168/199): loss=0.24944148051310916, w0=-0.6347058936905899, gamma=1.0\n",
      "Hessian Descent(169/199): loss=0.24944099585347532, w0=-0.6347300351559456, gamma=1.0\n",
      "Hessian Descent(170/199): loss=0.24944052324200805, w0=-0.6347539253598182, gamma=1.0\n",
      "Hessian Descent(171/199): loss=0.24944006261196539, w0=-0.6347775685186321, gamma=1.0\n",
      "Hessian Descent(172/199): loss=0.2494396138931271, w0=-0.6348009687369893, gamma=1.0\n",
      "Hessian Descent(173/199): loss=0.24943917702709367, w0=-0.634824130022522, gamma=1.0\n",
      "Hessian Descent(174/199): loss=0.2494387519487296, w0=-0.6348470562640354, gamma=1.0\n",
      "Hessian Descent(175/199): loss=0.2494383386051917, w0=-0.6348697512645315, gamma=1.0\n",
      "Hessian Descent(176/199): loss=0.24943793694070715, w0=-0.634892218719776, gamma=1.0\n",
      "Hessian Descent(177/199): loss=0.2494375469043857, w0=-0.6349144622277372, gamma=1.0\n",
      "Hessian Descent(178/199): loss=0.24943716844628905, w0=-0.634936485297111, gamma=1.0\n",
      "Hessian Descent(179/199): loss=0.24943680152396308, w0=-0.6349582913440415, gamma=1.0\n",
      "Hessian Descent(180/199): loss=0.24943644608981685, w0=-0.6349798836827527, gamma=1.0\n",
      "Hessian Descent(181/199): loss=0.24943610210470163, w0=-0.6350012655517663, gamma=1.0\n",
      "Hessian Descent(182/199): loss=0.2494357695294347, w0=-0.6350224401002998, gamma=1.0\n",
      "Hessian Descent(183/199): loss=0.24943544832589645, w0=-0.6350434103843335, gamma=1.0\n",
      "Hessian Descent(184/199): loss=0.24943513846087687, w0=-0.6350641793794306, gamma=1.0\n",
      "Hessian Descent(185/199): loss=0.24943483989947224, w0=-0.6350847499817046, gamma=1.0\n",
      "Hessian Descent(186/199): loss=0.24943455261127062, w0=-0.635105124997394, gamma=1.0\n",
      "Hessian Descent(187/199): loss=0.249434276566162, w0=-0.6351253071547017, gamma=1.0\n",
      "Hessian Descent(188/199): loss=0.24943401173480756, w0=-0.635145299107382, gamma=1.0\n",
      "Hessian Descent(189/199): loss=0.2494337580913193, w0=-0.6351651034222126, gamma=1.0\n",
      "Hessian Descent(190/199): loss=0.24943351560802524, w0=-0.6351847225946305, gamma=1.0\n",
      "Hessian Descent(191/199): loss=0.24943328426211434, w0=-0.6352041590375792, gamma=1.0\n",
      "Hessian Descent(192/199): loss=0.24943306402621235, w0=-0.6352234150874553, gamma=1.0\n",
      "Hessian Descent(193/199): loss=0.24943285487960634, w0=-0.635242493012017, gamma=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian Descent(194/199): loss=0.24943265679642276, w0=-0.6352613950018493, gamma=1.0\n",
      "Hessian Descent(195/199): loss=0.24943246975584732, w0=-0.6352801231735354, gamma=1.0\n",
      "Hessian Descent(196/199): loss=0.2494322937342825, w0=-0.635298679567244, gamma=1.0\n",
      "Hessian Descent(197/199): loss=0.2494321287079158, w0=-0.6353170661557266, gamma=1.0\n",
      "Hessian Descent(198/199): loss=0.24943197465520414, w0=-0.6353352848451578, gamma=1.0\n",
      "Hessian Descent(199/199): loss=0.24943183154951096, w0=-0.6353533374661985, gamma=1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24943183154951096"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((tX.shape[1]) )\n",
    "max_iters = 200 #choosing number of iterations\n",
    "gamma = 1.0\n",
    "#w,loss = adaptative_step_gradient_descent(y, tX, w, max_iters, gamma)\n",
    "w,loss = hessian_descent(y,tX,w,max_iters,gamma)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, xx, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test = xx.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = tX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tX.shape[1]):\n",
    "    col = tX[:,i]\n",
    "    places_999 = (col == -999.0)\n",
    "    mean_col = col[col!=-999.0].mean()\n",
    "    col[places_999] = mean_col\n",
    "    tX[:,i] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_columns = tX_test[:,np.all(tX_test > 0,axis=0)]\n",
    "positive_columns_log = np.log(positive_columns)\n",
    "not_zero_columns = tX_test[:, np.all(tX_test != 0,axis=0)]\n",
    "not_zero_columns_inv = 1 / not_zero_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 12)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_columns_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test = tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 241)\n",
      "(568238, 240)\n",
      "(568238, 338)\n"
     ]
    }
   ],
   "source": [
    "tX_test = build_poly(tX_test, degree)\n",
    "print(tX_test.shape)\n",
    "tX_test = tX_test[:,1:]\n",
    "print(tX_test.shape)\n",
    "tX_test = extend(tX_test,[np.cos,np.sin])\n",
    "#print(tX_test.shape)\n",
    "tX_test = np.c_[(tX_test, positive_columns_log)]\n",
    "tX_test = np.c_[(tX_test, not_zero_columns_inv)]\n",
    "tX_test = np.c_[(tX_test, not_zero_columns_inv**2)]\n",
    "print(tX_test.shape)\n",
    "tX_test = (tX_test-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 338)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test = np.c_[(np.ones(tX_test.shape[0]) , tX_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/output.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
