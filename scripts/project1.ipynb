{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): loss=0.5, w0=1.0766649510400013, w1=-0.27284198603999993\n",
      "Gradient Descent(1/49): loss=200809722.91839442, w0=-19134.00425346592, w1=8979.929433607711\n",
      "Gradient Descent(2/49): loss=6.601079608578582e+17, w0=1022092706.6918955, w1=-512753284.13136065\n",
      "Gradient Descent(3/49): loss=2.1707506422373964e+27, w0=-58447668465412.3, w1=29401215555910.9\n",
      "Gradient Descent(4/49): loss=7.13847659449749e+36, w0=3.3512037312508283e+18, w1=-1.686017718139715e+18\n",
      "Gradient Descent(5/49): loss=2.347475919145628e+46, w0=-1.9217381838024535e+23, w1=9.668518127410577e+22\n",
      "Gradient Descent(6/49): loss=7.719634740573102e+55, w0=1.1020255731786054e+28, w1=-5.544440387917798e+27\n",
      "Gradient Descent(7/49): loss=2.5385887898515216e+65, w0=-6.3195979051460835e+32, w1=3.179475782930356e+32\n",
      "Gradient Descent(8/49): loss=8.348106174103012e+74, w0=3.6239921391655987e+37, w1=-1.8232798167079269e+37\n",
      "Gradient Descent(9/49): loss=2.7452605547105108e+84, w0=-2.0781890384124145e+42, w1=1.0455652179693703e+42\n",
      "Gradient Descent(10/49): loss=9.027742767130351e+93, w0=1.1917436670583117e+47, w1=-5.995824749494401e+46\n",
      "Gradient Descent(11/49): loss=2.9687578954802903e+103, w0=-6.834089400805478e+51, w1=3.4383234836817267e+51\n",
      "Gradient Descent(12/49): loss=9.762709981133103e+112, w0=3.919028833913788e+56, w1=-1.9717167983327274e+56\n",
      "Gradient Descent(13/49): loss=3.210450617102152e+122, w0=-2.2473787069923087e+61, w1=1.1306868452832657e+61\n",
      "Gradient Descent(14/49): loss=1.055751239642511e+132, w0=1.2887659843009074e+66, w1=-6.483957245673786e+65\n",
      "Gradient Descent(15/49): loss=3.471820043171326e+141, w0=-7.39046675633016e+70, w1=3.718244511210633e+70\n",
      "Gradient Descent(16/49): loss=1.1417021320522057e+151, w0=4.238085078420918e+75, w1=-2.132238341696735e+75\n",
      "Gradient Descent(17/49): loss=3.75446809490128e+160, w0=-2.430342456591065e+80, w1=1.2227384003644637e+80\n",
      "Gradient Descent(18/49): loss=1.2346504644161493e+170, w0=1.3936870891015308e+85, w1=-7.01182961814732e+84\n",
      "Gradient Descent(19/49): loss=4.060127109225294e+179, w0=-7.992139943326229e+89, w1=4.0209544886521195e+89\n",
      "Gradient Descent(20/49): loss=1.33516591279634e+189, w0=4.5831163518123886e+94, w1=-2.3058282759705104e+94\n",
      "Gradient Descent(21/49): loss=4.390670456210015e+198, w0=-2.628201663534451e+99, w1=1.322284062968198e+99\n",
      "Gradient Descent(22/49): loss=1.4438645317614564e+208, w0=1.5071500380900707e+104, w1=-7.5826771724524e+103\n",
      "Gradient Descent(23/49): loss=4.748124020854581e+217, w0=-8.642796589132896e+108, w1=4.3483087115611417e+108\n",
      "Gradient Descent(24/49): loss=1.5614125301570143e+227, w0=4.95623733492308e+113, w1=-2.4935505258920754e+113\n",
      "Gradient Descent(25/49): loss=5.134678619646765e+236, w0=-2.842168997818543e+118, w1=1.4299339438906382e+118\n",
      "Gradient Descent(26/49): loss=1.6885303542687969e+246, w0=1.6298502404720374e+123, w1=-8.199998607043e+122\n",
      "Gradient Descent(27/49): loss=5.55270342797667e+255, w0=-9.346424538462133e+127, w1=4.7023135189417915e+127\n",
      "Gradient Descent(28/49): loss=1.8259971034050867e+265, w0=5.359734869129272e+132, w1=-2.6965556325132713e+132\n",
      "Gradient Descent(29/49): loss=6.0047605007039355e+274, w0=-3.0735558554123747e+137, w1=1.546347824309981e+137\n",
      "Gradient Descent(30/49): loss=1.9746553049605287e+284, w0=1.7625397201549242e+142, w1=-8.867577456651785e+141\n",
      "Gradient Descent(31/49): loss=6.493620474874313e+293, w0=-1.010733629471326e+147, w1=5.085138590006905e+146\n",
      "Gradient Descent(32/49): loss=inf, w0=5.796081972294422e+151, w1=-2.9160878048130504e+151\n",
      "Gradient Descent(33/49): loss=inf, w0=-3.323780395743666e+156, w1=1.6722391995550024e+156\n",
      "Gradient Descent(34/49): loss=inf, w0=1.9060317248682165e+161, w1=-9.589505281400919e+160\n",
      "Gradient Descent(35/49): loss=inf, w0=-1.0930195451108529e+166, w1=5.499130242042341e+165\n",
      "Gradient Descent(36/49): loss=inf, w0=6.267952995782046e+170, w1=-3.153492545397185e+170\n",
      "Gradient Descent(37/49): loss=inf, w0=-3.594376233532825e+175, w1=1.8083796520851757e+175\n",
      "Gradient Descent(38/49): loss=inf, w0=2.061205710521397e+180, w1=-1.0370206743786113e+180\n",
      "Gradient Descent(39/49): loss=inf, w0=-1.1820045273641814e+185, w1=5.9468258108779864e+184\n",
      "Gradient Descent(40/49): loss=inf, w0=6.778240015432549e+189, w1=-3.4102248970219786e+189\n",
      "Gradient Descent(41/49): loss=inf, w0=-3.887001838247216e+194, w1=1.9556035804841528e+194\n",
      "Gradient Descent(42/49): loss=inf, w0=2.229012731348825e+199, w1=-1.1214466727230018e+199\n",
      "Gradient Descent(43/49): loss=inf, w0=-1.2782339611024294e+204, w1=6.43096920210247e+203\n",
      "Gradient Descent(44/49): loss=inf, w0=7.330070556963155e+208, w1=-3.6878583604844984e+208\n",
      "Gradient Descent(45/49): loss=inf, w0=-4.20345069878428e+213, w1=2.1148133134503455e+213\n",
      "Gradient Descent(46/49): loss=inf, w0=2.4104812688774935e+218, w1=-1.2127459662412941e+218\n",
      "Gradient Descent(47/49): loss=inf, w0=-1.3822976321072897e+223, w1=6.954527708334609e+222\n",
      "Gradient Descent(48/49): loss=inf, w0=7.926826764429545e+227, w1=-3.988094538536749e+227\n",
      "Gradient Descent(49/49): loss=inf, w0=-4.5456623156827835e+232, w1=2.2869846401281188e+232\n"
     ]
    }
   ],
   "source": [
    "w = np.array(np.zeros((tX.shape[1]))) #initializing the weights to zero\n",
    "gamma = 0.01 #choosing gamma \n",
    "max_iters = 50 #choosing number of iterations\n",
    "\n",
    "(w, loss) = least_squares_GD(y,tX,w,max_iters,gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
